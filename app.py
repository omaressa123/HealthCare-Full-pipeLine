import streamlit as st
import pandas as pd
import numpy as np
import joblib
import io
from pathlib import Path
import sys
import importlib

# ============================
# Page / Theming
# ============================
st.set_page_config(
    page_title="ML Model Demo",
    page_icon="ü§ñ",
    layout="wide",
)

# Minimal custom styling
st.markdown(
    """
    <style>
      :root {
        --accent: #5b9bd5; /* Soft blue */
        --bg: #0e1117;
        --card: #111827;
        --muted: #6b7280;
      }
      .accent { color: var(--accent) !important; }
      .card {
        background: var(--card);
        padding: 1rem 1.25rem; border-radius: 1rem;
        border: 1px solid rgba(255,255,255,0.06);
      }
      .small { font-size: 0.9rem; color: var(--muted); }
      .metric-pill {
        display:inline-block; padding: .35rem .65rem; border-radius: 999px;
        background: rgba(91,155,213,.1); color: var(--accent); font-weight: 600;
        border: 1px solid rgba(91,155,213,.25);
      }
      .stButton>button {
        border-radius: 12px; font-weight: 600; border: 1px solid rgba(255,255,255,0.15);
      }
    </style>
    """,
    unsafe_allow_html=True,
)

# ============================
# Helpers
# ============================
@st.cache_resource(show_spinner=False)
def load_model_from_bytes(file_bytes: bytes):
    # Try to load the model, and if it fails due to missing module, prompt user to install it
    try:
        model = joblib.load(io.BytesIO(file_bytes))
        if not hasattr(model, "predict"):
            raise ValueError(f"Loaded object is of type {type(model)} and does not have a 'predict' method.")
        return model
    except ModuleNotFoundError as e:
        missing_module = str(e).split("'")[1]
        st.error(
            f"Failed to load model: Missing required Python module: {missing_module}.\n"
            f"Please install it in your environment (e.g., pip install {missing_module}) and reload the app."
        )
        return None
    except AttributeError as e:
        st.error(
            f"Failed to load model: {e}.\n"
            "This may be due to version mismatch between the environment where the model was saved and the current environment.\n"
            "Try to use the same library versions as used during model training."
        )
        return None
    except Exception as e:
        st.error(f"Failed to load model: {e}")
        return None

def is_classifier(model) -> bool:
    # For XGBoost and sklearn models
    try:
        from sklearn.base import is_classifier as sk_is_classifier
        return sk_is_classifier(model)
    except Exception:
        return hasattr(model, "predict_proba")

# ============================
# Sidebar ‚Äì Model upload & options
# ============================
st.sidebar.header("‚öôÔ∏è Settings")

# Upload model file (for your use: joblib.dump(models, 'best2_model.pkl'))
model_file = st.sidebar.file_uploader(
    "Upload your model (.pkl)", type=["pkl", "joblib"], key="model_uploader",
    help="Upload a scikit-learn or XGBoost model file (joblib or pickle format)"
)

model = None
model_status = ""
inferred_n_features = None
model_load_error = None

if model_file is not None:
    try:
        model = load_model_from_bytes(model_file.getvalue())
        if model is not None:
            model_status = f"‚úÖ Model loaded from **{model_file.name}**<br>Type: <code>{type(model).__name__}</code>"
            for attr in ["n_features_in_", "n_features_"]:
                if hasattr(model, attr):
                    inferred_n_features = int(getattr(model, attr))
                    break
        else:
            model_status = f"‚ùå Failed to load model from {model_file.name}. See error message above."
    except Exception as e:
        model_status = f"‚ùå Failed to load model from {model_file.name}: {e}"
else:
    model_status = "No model uploaded. Please upload a .pkl or .joblib file."

st.sidebar.markdown(f"**Model status:** {model_status}", unsafe_allow_html=True)

# Configure feature inputs
st.sidebar.divider()
st.sidebar.subheader("üßÆ Input settings")

n_features = st.sidebar.number_input(
    "Number of features", min_value=1, max_value=200,
    value=int(inferred_n_features or 4), step=1, key="n_features_input",
    help="The system can try to infer the number, or you can set it manually"
)

# Sample data to infer features (optional, keep for UI completeness)
st.sidebar.markdown("**Infer feature inputs from data**")
sample_data_file = st.sidebar.file_uploader(
    "Sample data (CSV)", type=["csv"], key="sample_data_uploader",
    help="Upload a small CSV with your input columns to auto-generate inputs"
)
use_bundled = False
if sample_data_file is None and Path("Healthcare-Diabetes.csv").exists():
    use_bundled = st.sidebar.checkbox("Use bundled Healthcare-Diabetes.csv", value=False, key="use_bundled_checkbox")

sample_df = None
if sample_data_file is not None:
    try:
        sample_df = pd.read_csv(sample_data_file)
    except Exception as e:
        st.sidebar.error(f"Failed to read CSV: {e}")
elif use_bundled:
    try:
        sample_df = pd.read_csv("Healthcare-Diabetes.csv")
    except Exception as e:
        st.sidebar.error(f"Failed to read bundled CSV: {e}")

target_column = None
feature_columns = None
if sample_df is not None:
    all_cols = list(sample_df.columns)
    guess_targets = [c for c in all_cols if c.lower() in ["target", "label", "outcome", "y"]]
    target_opts = ["<none>"] + all_cols
    target_idx = 0
    if guess_targets:
        try:
            target_idx = 1 + all_cols.index(guess_targets[0])
        except Exception:
            target_idx = 0
    target_column = st.sidebar.selectbox(
        "Target column (exclude)", options=target_opts, index=target_idx, key="target_column_select"
    )

    excluded_cols = set()
    if target_column and target_column != "<none>":
        excluded_cols.add(target_column)

    id_like = [c for c in all_cols if c.lower() == "id" or c.lower().endswith("id")]
    default_id_like = [c for c in id_like[:1]]
    if id_like:
        excluded_ids = st.sidebar.multiselect(
            "Exclude ID-like columns", id_like, default=default_id_like, key="exclude_ids_multiselect"
        )
        excluded_cols.update(excluded_ids)

    feature_columns = [c for c in all_cols if c not in excluded_cols]

show_prob = st.sidebar.checkbox(
    "Show prediction probabilities (for Classification)", value=True, key="show_prob_checkbox"
)

# ============================
# Header
# ============================
st.markdown("""
# ü§ñ <span class="accent">ML Model Deployment</span>
A simple **Streamlit** interface to upload your model and try predictions with your own inputs.
""", unsafe_allow_html=True)

# ============================
# Prediction Section
# ============================
st.markdown("### üîÆ Predict using the model")

if model is None:
    st.warning("No model loaded yet. Please upload a .pkl or .joblib model file in the sidebar.")
else:
    if not hasattr(model, "predict"):
        st.error(f"Loaded model is of type {type(model)} and does not have a 'predict' method. Ensure the .pkl file contains a valid scikit-learn or XGBoost model.")
    else:
        problem_type = "Classification" if is_classifier(model) else "Regression"
        st.markdown(f"**Detected problem type:** {problem_type}")

        with st.form("predict_form"):
            inputs = []
            ui_mode = "count"

            if sample_df is not None and feature_columns:
                ui_mode = "sample_df"
                st.markdown("**Input features**")
                cols = st.columns(4)
                for i, col_name in enumerate(feature_columns[:n_features]):
                    with cols[i % 4]:
                        if pd.api.types.is_numeric_dtype(sample_df[col_name]):
                            value = st.number_input(
                                col_name, value=0.0, step=0.1, format="%.4f", key=f"input_{col_name}"
                            )
                        else:
                            value = st.text_input(col_name, value="", key=f"input_{col_name}")
                        inputs.append((col_name, value))
            else:
                ui_mode = "count"
                st.markdown("**Input features (generic)**")
                cols = st.columns(4)
                for i in range(n_features):
                    with cols[i % 4]:
                        value = st.number_input(
                            f"Feature {i+1}", value=0.0, step=0.1, format="%.4f", key=f"feature_{i}"
                        )
                        inputs.append(value)

            submitted = st.form_submit_button("Predict")

            if submitted:
                try:
                    if ui_mode == "sample_df":
                        row_dict = {name: value for name, value in inputs}
                        X = pd.DataFrame([row_dict])
                    else:
                        X = np.array(inputs, dtype=float).reshape(1, -1)

                    y_pred = model.predict(X)
                    st.success(f"Output: {y_pred[0]}")

                    if show_prob and hasattr(model, "predict_proba"):
                        try:
                            proba = model.predict_proba(X)[0]
                            # For XGBoost, class labels may be in model.classes_
                            class_labels = getattr(model, "classes_", list(range(len(proba))))
                            prob_df = pd.DataFrame({"Class": class_labels, "Probability": proba})
                            st.markdown("**Class probabilities:**")
                            st.dataframe(prob_df, use_container_width=True)
                            st.bar_chart(prob_df.set_index("Class"))
                        except Exception:
                            pass
                except Exception as e:
                    st.error(f"An error occurred during prediction: {e}")

# ============================
# Footer / Tips
# ============================
st.divider()
st.markdown("Finished")
